---
title: "CARPS Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r}
articleID <- "1-1-2015_PS" # insert the article ID code here e.g., "10-3-2015_PS"
reportType <- 'pilot'
pilotNames <- "Marc B. Harrison, Gobi Dasu" # insert the pilot's name here e.g., "Tom Hardwicke". If there are multiple pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
copilotNames <- "" # insert the co-pilot's name here e.g., "Michael Frank". If there are multiple co-pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
pilotTTC <- 120 # insert the pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
copilotTTC <- NA # insert the co- pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
pilotStartDate <- as.Date("10/26/2017", format = "%m/%d/%y") # insert the pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- as.Date("", format = "%m/%d/%y") # insert the co-pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- as.Date("", format = "%m/%d/%y") # copilot insert the date of final report completion (after any necessary rounds of author assistance) in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

-------

#### Methods summary: 
A sense of power has often been tied to how we perceive each other's voice. Social hierarchy is embedded into the structure of society and provides a metric by which others relate to one another. In 1956, the Brunswik Lens Model was introduced to examine how vocal cues might influence hierarchy. In “The Sound of Power: Conveying and Detecting Hierarchical Rank Through Voice,” Ko and colleagues investigated how manipulation of hierarchal rank within a situation might impact vocal acoustic cues. Using the Brunswik Model, six acoustic metrics were utilized (pitch mean & variability, loudness mean & variability, and resonance mean & variability) to isolate a potential contribution between individuals of different hierarchal rank. In the first experiment, Ko, Sadler & Galinsky examined the effect of individuals before and after being assigned a hierarchal rank in a sample of 161 subjects (80 female). Each of the six hierarchy acoustic cues were analyzed with a 2 (high vs. low rank condition)  x 2 analysis of covariance (male vs. female).

------

#### Target outcomes: 
The impact of hierarchical rank on speakers’ acoustic cues. Each of the six hierarchy-based (i.e., postmanipulation) acoustic variables was submitted to a 2 (condition: high rank, low rank) × 2 (speaker’s sex: female, male) between-subjects analysis of covariance, controlling for the corresponding baseline acoustic variable. Table 4 presents the adjusted means by condition. Condition had a significant effect on pitch, pitch variability, and loudness variability. Speakers’ voices in the high-rank condition had higher pitch, F(1, 156) = 4.48, p < .05; were more variable in loudness, F(1, 156) = 4.66,
p < .05; and were more monotone (i.e., less variable in pitch), F(1, 156) = 4.73, p < .05, compared with speakers’ voices in the low-rank condition (all other Fs < 1; see the Supplemental Material for additional analyses of covariance involving pitch and loudness).  

------

[The chunk below sets up some formatting options for the R Markdown document]

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## Step 1: Load packages

[Some useful packages are being loaded below. You can add any additional ones you might need too.]

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CARPSreports) # custom report functions
library(psych)
```

```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared.
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

## Step 2: Load data

```{r}
sound <-read_csv("data/S1_voice_level_Final.csv")
#DT::datatable(sound)
```

## Step 3: Tidy data

```{r}
d.tidy <- sound %>% 
    rename(pitch_mean = pitch_rmean,
         pitch_var = pitch_rvar,          
         loud_mean = intense_rmean,
         loud_var = intense_rvar, 
         res_mean = form_rmean,
         res_var = form_rvar,
         pitch_mean_p = pitch_smean,
         pitch_var_p = pitch_svar,          
         loud_mean_p = intense_smean,
         loud_var_p = intense_svar, 
         res_mean_p = form_smean,
         res_var_p = form_svar)

```

## Step 4: Run analysis

### Pre-processing

[you can remove this section if no pre-processing is required]

```{r}

```

### Descriptive statistics

```{r}
```

### Inferential statistics

```{r}
myvars2 <- c("pitch_mean", "pitch_var", "loud_mean","loud_var","res_mean","res_var","pitch_mean_p","pitch_var_p", "loud_mean_p","loud_var_p","res_mean_p","res_var_p","plev", "vsex")
sound_power <- d.tidy[myvars2]

sound_power$plev <- as.factor(sound_power$plev)
sound_power$vsex <- as.factor(sound_power$vsex)

## load packages for ANCOVA
library(car)
library(compute.es)
#library(effects)
library(ggplot2)
#library(multcomp)
#library(pastecs)
library(psych)
library(lsmeans)
#library(rcompanion)
#library(Rmisc)
#library(multcompView)
#library(FSA)

contrasts(sound_power$plev)<-cbind(c(1,-1))
contrasts(sound_power$vsex)<-cbind(c(-1,1))

# ANCOVA 2x2 tests & adjusted means

model1 <-aov(pitch_mean_p ~ plev + vsex + pitch_mean + plev:vsex, data=sound_power)
Anova(model1, type="III")

lsmeans(model1,
        pairwise ~ plev,
        adjust="tukey")

reportObject <- reproCheck(reportedValue = "1", obtainedValue = 1, valueType = 'df')
reportObject <- reproCheck(reportedValue = "156", obtainedValue = 156, valueType = 'df')

model2 <-aov(pitch_var_p ~ plev + vsex + pitch_var + plev:vsex, data=sound_power)
Anova(model2, type="III")

lsmeans(model2,
        pairwise ~ plev,
        adjust="tukey")

model3 <-aov(loud_mean_p ~ plev + vsex + loud_mean + plev:vsex, data=sound_power)
Anova(model3, type="III")


lsmeans(model3,
        pairwise ~ plev,
        adjust="tukey")

model4 <-aov(loud_var_p ~ plev + vsex + loud_var + plev:vsex, data=sound_power)
Anova(model4, type="III")

lsmeans(model4,
        pairwise ~ plev,
        adjust="tukey")

model5 <-aov(res_mean_p ~ plev + vsex + res_mean + plev:vsex, data=sound_power)
Anova(model5, type="III")

lsmeans(model5,
        pairwise ~ plev,
        adjust="tukey")


model6 <-aov(res_var_p ~ plev + vsex + res_var + plev:vsex, data=sound_power)
Anova(model6, type="III")
lsmeans(model6,
        pairwise ~ plev,
        adjust="tukey")
```

## Step 5: Conclusion

All reported tests aligned with ANOCVA's produced in this replication minus one minor numerical error for a F-value in model3: loudness mean with sex; p-value was still significant, thus replication of experiment #1 was a SUCCESS. 

```{r}
Author_Assistance = FALSE # was author assistance provided? (if so, enter TRUE)

Insufficient_Information_Errors <- 0 # how many discrete insufficient information issues did you encounter?

# Assess the causal locus (discrete reproducibility issues) of any reproducibility errors. Note that there doesn't necessarily have to be a one-to-one correspondance between discrete reproducibility issues and reproducibility errors. For example, it could be that the original article neglects to mention that a Greenhouse-Geisser correct was applied to ANOVA outcomes. This might result in multiple reproducibility errors, but there is a single causal locus (discrete reproducibility issue).

locus_typo <- NA # how many discrete issues did you encounter that related to typographical errors?
locus_specification <- NA # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis <- NA # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data <- NA # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified <- NA # how many discrete issues were there for which you could not identify the cause

Affects_Conclusion <- NA # Do any reproducibility issues encounter appear to affect the conclusions made in the original article? This is a subjective judgement, but you should taking into account multiple factors, such as the presence/absence of decision errors, the number of target outcomes that could not be reproduced, the type of outcomes that could or could not be reproduced, the difference in magnitude of effect sizes, and the predictions of the specific hypothesis under scrutiny.
```

```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add the articleID 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome != "MATCH") | Insufficient_Information_Errors > 0){
  finalOutcome <- "Failure without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Failure despite author assistance"
  }
}else{
  finalOutcome <- "Success without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Success with author assistance"
  }
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, Author_Assistance, finalOutcome, Insufficient_Information_Errors, locus_typo, locus_specification, locus_analysis, locus_data, locus_unidentified)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "final"){
  write_csv(reportObject, "finalReportDetailed.csv")
  write_csv(reportExtras, "finalReportExtras.csv")
}
```

# Session information

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
